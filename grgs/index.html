<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Projectpage of GRGS</title>
    <!-- Bootstrap -->
    <link href="./static/css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2>Generalizable and Relightable Gaussian Splatting<br>for Human Novel View Synthesis</h2>
            <!-- <h4 style="color:#5a6268;">CVPR 2024 Highlight</h4> -->
            <hr>
            <h6> <a href="https://sillybirrrd.github.io" target="_blank">Yipengjing Sun<sup>1</sup></a>,
                <a>Chenyang Wang<sup>1</sup></a>,
                <a href="https://shunyuanzheng.github.io" target="_blank">Shunyuan Zheng<sup>1</sup></a>,
                <a>Zonglin Li<sup>1</sup></a>,
                <a href="http://homepage.hit.edu.cn/zhangshengping" target="_blank">Shengping Zhang<sup>&#x2709,1</sup></a>,
                <a>Xiangyang Ji<sup>2</sup></a></h6>
            <p><sup>1</sup>Harbin Institute of Technology<sup>&nbsp;&nbsp;&nbsp;&nbsp;2</sup>Tsinghua University
            <br><sup>&#x2709</sup>Corresponding author 
            </p>
            <!-- <p>*Corresponding author</p> -->
            <!-- <p> <a class="btn btn-secondary btn-lg" href="" role="button">Paper</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Code</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Data</a> </p> -->

            <div class="row justify-content-center">
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="" role="button"  target="_blank">
                  <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="" role="button"  target="_blank">
                  <i class="fa fa-youtube"></i> Video</a></p>
              <!-- </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/ShunyuanZheng/GPS-Gaussian" role="button"  target="_blank">
                  <i class="fa fa-github"></i> Code</a></p> -->
              <!-- </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://yaourtb.github.io/GPS-Gaussian+" role="button"  target="_blank">
                  <i class="fa fa-forward"></i> Extension</a></p> -->
              </div>
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>


  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
            <video width="90%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="../images/GRGS.mp4" type="video/mp4">
            </video>
<!--             <img src="../images/GRGS.mp4" width="100%" alt=""/> -->
              <!-- <br><br> -->
          <p class="text-left"> We propose GRGS, a generalizable and relightable 3D Gaussian framework for high-fidelity human novel view synthesis under diverse lighting conditions. Unlike existing methods that rely on per-character optimization or ignore physical constraints, GRGS adopts a feed-forward, fully supervised strategy that projects geometry, material, and illumination cues from multi-view 2D observations into 3D Gaussian representations. Specifically, to reconstruct lighting-invariant geometry, we introduce a Lighting-aware Geometry Refinement (LGR) module trained on synthetically relit data to predict accurate depth and surface normals. Based on the high-quality geometry, a Physically Grounded Neural Rendering (PGNR) module is further proposed to integrate neural prediction with physics-based shading, supporting editable relighting with shadows and indirect illumination. Besides, we design a 2D-to-3D projection training scheme that leverages differentiable supervision from ambient occlusion, direct, and indirect lighting maps, which alleviates the computational cost of explicit ray tracing. Extensive experiments demonstrate that GRGS achieves superior visual quality, geometric consistency, and generalization across characters and lighting conditions. 
            </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Free View Rendering</h3>
            <hr style="margin-top:0px">
          <h6 style="color:#8899a5"> Data collected by ourselves</h6>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/GPS-Gaussian/videos/zsy_freeview.mp4" type="video/mp4">
            </video>
          <h6 style="color:#8899a5"> Data from <a href="https://dna-rendering.github.io/" target="_blank">DNA-Rendering</a></h6>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/GPS-Gaussian/videos/dna173_freeview.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/GPS-Gaussian/videos/dna188_freeview.mp4" type="video/mp4">
            </video>
              <!-- <br><br> -->
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Live Demo</h3>
            <hr style="margin-top:0px">
          <h6 style="color:#8899a5"> Live demo for handling challenging hairstyles, human-object interaction and multi-person scenario</h6>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/GPS-Gaussian/videos/wcy_live.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/GPS-Gaussian/videos/jds_live.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/GPS-Gaussian/videos/zby_live.mp4" type="video/mp4">
            </video>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
              <source src="assets/GPS-Gaussian/videos/multi_live.mp4" type="video/mp4">
            </video>
              <!-- <br><br> -->
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
          <div class="col-12 text-center">
            <h3>Method</h3>
              <hr style="margin-top:0px">
            <img src="resources/pipeline_v4.pdf" width="100%" alt=""/>
            <p>&nbsp;</p>
            <p>
              <b>Overview of GRGS.</b> Given sparse-view images of a performer under arbitrary illumination, GRGS first leverages the LGR module to reconstruct accurate depth and surface normals, and then employs the PGNR module for material decomposition and physically plausible realistic relighting from novel viewpoints.
            </p>
            <p>&nbsp;</p>
          </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Demo Video</h3>
            <hr style="margin-top:0px">
            If the video does not play, please click <a href="assets/GPS-Gaussian/videos/youtube_video.mp4" target="_blank">here</a> to watch it.
            <div class="embed-responsive embed-responsive-16by9">
                <iframe style="clip-path: inset(1px 1px)" width="100%" height="100%" src="https://www.youtube.com/embed/HjnBAqjGIAo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@inproceedings{zheng2024gpsgaussian,
  title={GPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for Real-time Human Novel View Synthesis},
  author={Zheng, Shunyuan and Zhou, Boyao and Shao, Ruizhi and Liu, Boning and Zhang, Shengping and Nie, Liqiang and Liu, Yebin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}</code></pre>
          <hr>
      </div>
    </div>
  </div>

  <footer class="text-center" style="margin-bottom:10px">
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
  </footer>

</body>
</html>
